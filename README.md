# LITA_Class_Documents
This repository contains my Data Analysis Project with the Incubator Hub
Project Title: Data Analysis (Beginner Level)
Project Overview: Learning Data Analysis
This is my learning Journey/process in Data Analysis sponsored by INCUBATOR HUB/LADIES IN TECH AFRICA. This project is a learning process of Data analysis as a data analyst, gaining knowledge on foundations of Data,Data entry,Data literacy, ETL,Tools for cleaning Data, how to create database and how to query data, Data visualization,how to build data inform report and presentation of Data.

Lessons learnt.
Operational System
Analytic System
Bespoke/Custom systems
Data Analysis Tools
Microsft Excell SQL Database server(Structured Query Language) Github for building of Portfolio

Microsoft Excel Download here
Excell Interface Data entry fundamentals

shortcuts
Autofits
Form
Formatting in excel
Data Validation
Excel Functions(Aggregation)
sum, sumIf
Min, MinIf
max, MaxIf
Large,LargeIf
Count, CountIf
Average,AverageIf
Exel Functions 2
Text Extraction( LEFT,MID,RIGHT,SEARCH,FIND)

Composition(CCombining more than one functions to extract text)

The use of Flashfil(Control+ E)

Text-cleaning( LOWER,UPPER,PROPER)

Generating Random numbers (RANDBETWEEN)

Trim Functions (TRIM)

Excel Functions 3

VLOOKUP

HLOOKUP

INDEX

MATCH

INDEX x MATCH

XLOOKUP

CHOOSE

INDIRECT

Cell Referencing

Excel Functions 4

Conditional Functions

IFS

AND

SWITCH

OR

XOR

Creating report in Excel using Pivot Tools
Pivot Tables
SQL(STRUCTURED QUERY LANGUAGE)
SQL commands

Data type

Database keys

SQL Operators

SQL Clauses

Syntax

writing codes e.g
SELECT * FROM TABLE EMPLOYEE
WHERE STAFFID = AB200
POWER BI(BUSINESS INTELLIGENCE)
-Installation and Introduction to Power BI

The Assignment on Text cleaning Using Power BI.
To clean the three files, was a step by step process done step by step to bring the data in a good shape and state for analysis and visualization. The whole process is captured in a called data analysis term E T L (Extract, Transform and Load) E- EXTRACT : The extraction phase, I simply got my data from my file explorer by Clicking on the Get Data tab under Home menu and I selected my desired files I needed, I checked the boxes to confirm I am not picking an empty file. Then I clicked on Transform, since it is imperative to always take any new dataset to Transform in order to clean and transform the data into our desired form.

T- TRANSFORM : This phase is when I loaded my dataset in the transform tab, First, i checked my column quality, profile and distribution under the View Tab , this was to know the state of my dataset( each columns) so I know exactly what is wrong and what to do to get it to 100% . I worked with each file individually to clean, adjust and transform my datasets to the desired form. by removing null rows, promoted headers, removing null columns. I also used the proper functions, lower, upper and Trim to get the data in the desired state. I merged some columns to join two columns together. I also used Column example under Add Column "selected example" to insert literal (email "@lita.org" to fill the email with first name in Text cleaning 2). The Applied steps bar is well captured in the screenshots to show how I was able to clean each datasets. Lastly, I used the View menu to check my column quality before loading the datasets.

L- LOAD : This is the last phase after I cleaned my extracted and transform data with the tools from the Transform tab, I clicked on close and apply under Home menu to load my datasets. It was an amazing and exciting process.
